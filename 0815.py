#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ê³¤ì§€ì•” ë¦¬ì¡°íŠ¸ ì‹ìŒì—…ì¥ ìˆ˜ìš”ì˜ˆì¸¡ ê³ ë„í™” ML ëª¨ë¸ v3.1
- ë°ì´í„° í˜•ì‹ ë¬¸ì œ í•´ê²°
- Rolling features ì•ˆì •í™”
- í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜ ì²´ê³„ì  Feature Engineering
- ì‹¤ì „ìš© ì¥ì‹œê°„ í•™ìŠµ ì½”ë“œ
"""

# ========================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ========================================
import pandas as pd
import numpy as np
import warnings

warnings.filterwarnings('ignore')

from datetime import datetime, timedelta
import glob
import os
import re
from tqdm import tqdm
import pickle
import time
import gc
from collections import defaultdict

# ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'AppleGothic'  # macOS í•œê¸€ í°íŠ¸
plt.rcParams['axes.unicode_minus'] = False

# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge
from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression

# ë¶€ìŠ¤íŒ… ëª¨ë¸
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor

# ì‹œê³„ì—´ ë° í†µê³„
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from scipy.stats import pearsonr, spearmanr
import holidays


# ========================================
# 2. í‰ê°€ ë©”íŠ¸ë¦­ ë° ìœ í‹¸ë¦¬í‹°
# ========================================

def smape(y_true, y_pred):
    """Symmetric Mean Absolute Percentage Error - ëŒ€íšŒ í‰ê°€ì§€í‘œ"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0.0
    return 100 * np.mean(diff)


def weighted_smape(y_true, y_pred, weights):
    """ì—…ì¥ë³„ ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ sMAPE"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    weights = np.array(weights)

    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0.0

    weighted_diff = diff * weights
    return 100 * np.sum(weighted_diff) / np.sum(weights)


def print_section(title, emoji="ğŸ”"):
    """ì„¹ì…˜ ì œëª© ì¶œë ¥"""
    print("\n" + "=" * 70)
    print(f"{emoji} {title}")
    print("=" * 70)


# ========================================
# 3. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
# ========================================

class DomainFeatureEngineer:
    """í”„ë¡œì íŠ¸ ì§€ì‹ì„ í™œìš©í•œ ë„ë©”ì¸ íŠ¹í™” íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""

    def __init__(self):
        self.kr_holidays = holidays.KR(years=range(2023, 2026))
        self.menu_categories = self._init_menu_categories()
        self.restaurant_info = self._init_restaurant_info()
        self.menu_associations = self._init_menu_associations()

    def _init_menu_categories(self):
        """ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ì •ì˜ - í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜"""
        return {
            'ë©”ì¸ë©”ë‰´': ['ë³¸ì‚¼ê²¹', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„íƒ•', 'êµ­ë°¥', 'í•´ì¥êµ­', 'ëƒ‰ë©´', 'ë¹„ë¹”ë°¥',
                     'íŒŒìŠ¤íƒ€', 'í”¼ì', 'ë¦¬ì¡°ë˜', 'í”Œë˜í„°', 'ë¸ŒëŸ°ì¹˜', 'ì •ì‹', 'ëˆê¹ŒìŠ¤',
                     'ë³¶ìŒë°¥', 'ìš°ë™', 'ì§œì¥ë©´', 'ì§¬ë½•', 'ë–¡ë³¶ì´', 'ìˆœëŒ€', 'íŒŒì „', 'ê¼¬ì¹˜ì–´ë¬µ'],
            'ì‚¬ì´ë“œë©”ë‰´': ['ê³µê¹ƒë°¥', 'ë¼ë©´ì‚¬ë¦¬', 'ë©”ë°€ë©´ì‚¬ë¦¬', 'ìŒˆì•¼ì±„ì„¸íŠ¸', 'ìŒˆì¥',
                      'ì•¼ì±„ì¶”ê°€', 'ê³ ê¸°ì¶”ê°€', 'ë©´ì¶”ê°€', 'ë¹µì¶”ê°€', 'í–‡ë°˜'],
            'ì£¼ë¥˜': ['ë§‰ê±¸ë¦¬', 'ì†Œì£¼', 'ë§¥ì£¼', 'ì™€ì¸', 'ì¹µí…Œì¼', 'í•˜ì´ë³¼', 'ì°¸ì´ìŠ¬',
                   'ì²˜ìŒì²˜ëŸ¼', 'ì¹´ìŠ¤', 'í…Œë¼', 'ë²„ë“œì™€ì´ì €', 'ìŠ¤í…”ë¼', 'í•˜ì´ë„¤ì¼„'],
            'ìŒë£Œ': ['ì•„ë©”ë¦¬ì¹´ë…¸', 'ë¼ë–¼', 'ìŠ¤í”„ë¼ì´íŠ¸', 'ì½œë¼', 'ì œë¡œì½œë¼', 'ì—ì´ë“œ',
                   'ì•„ì´ìŠ¤í‹°', 'ì‹í˜œ', 'ìƒìˆ˜'],
            'ì•„ì´ìŠ¤í¬ë¦¼': ['ì•„ì´ìŠ¤í¬ë¦¼', 'ë»¥ìŠ¤í¬ë¦¼'],
            'ì¥ì†Œ': ['ëŒ€ì—¬ë£Œ', 'ë£¸', 'ì´ìš©ë£Œ', 'Conference', 'Convention', 'Grand', 'OPUS']
        }

    def _init_restaurant_info(self):
        """ì—…ì¥ë³„ íŠ¹ì„± ì •ì˜ - í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜"""
        return {
            'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ': {
                'type': 'outdoor_bbq',
                'season_preference': 'summer',
                'time_preference': 'evening',
                'customer_type': 'group',
                'weight': 1.0
            },
            'ë‹´í•˜': {
                'type': 'traditional_korean',
                'season_preference': 'all',
                'time_preference': 'lunch_dinner',
                'customer_type': 'family',
                'weight': 2.0  # ë†’ì€ ê°€ì¤‘ì¹˜
            },
            'ë¼ê·¸ë¡œíƒ€': {
                'type': 'italian_wine',
                'season_preference': 'all',
                'time_preference': 'dinner',
                'customer_type': 'couple',
                'weight': 1.0
            },
            'ë¯¸ë¼ì‹œì•„': {
                'type': 'brunch_buffet',
                'season_preference': 'all',
                'time_preference': 'brunch',
                'customer_type': 'family_with_kids',
                'weight': 2.0  # ë†’ì€ ê°€ì¤‘ì¹˜
            },
            'ì—°íšŒì¥': {
                'type': 'conference',
                'season_preference': 'all',
                'time_preference': 'business_hours',
                'customer_type': 'business',
                'weight': 1.0
            },
            'ì¹´í˜í…Œë¦¬ì•„': {
                'type': 'casual_dining',
                'season_preference': 'winter',
                'time_preference': 'all_day',
                'customer_type': 'ski_guests',
                'weight': 1.0
            },
            'í¬ë ˆìŠ¤íŠ¸ë¦¿': {
                'type': 'snack',
                'season_preference': 'winter',
                'time_preference': 'all_day',
                'customer_type': 'ski_guests',
                'weight': 1.0
            },
            'í™”ë‹´ìˆ²ì£¼ë§‰': {
                'type': 'korean_pub',
                'season_preference': 'spring_fall',
                'time_preference': 'evening',
                'customer_type': 'forest_visitors',
                'weight': 1.0
            },
            'í™”ë‹´ìˆ²ì¹´í˜': {
                'type': 'cafe',
                'season_preference': 'spring_fall',
                'time_preference': 'afternoon',
                'customer_type': 'forest_visitors',
                'weight': 1.0
            }
        }

    def _init_menu_associations(self):
        """ë©”ë‰´ ì—°ê´€ê´€ê³„ ì •ì˜ - í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜"""
        return {
            # ì—…ì¥ ë‚´ ì¢…ì†ê´€ê³„ (A â†’ B)
            'internal_dependencies': {
                'ì°¸ì´ìŠ¬': ['ì¼íšŒìš© ì†Œì£¼ì»µ'],
                'ìŠ¤í”„ë¼ì´íŠ¸': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
                'ì¹´ìŠ¤': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
                'ì½œë¼': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
                'ìƒëª©ì‚´ ê¹€ì¹˜ì „ê³¨': ['ë¼ë©´ì‚¬ë¦¬'],
                'ìƒëª©ì‚´ ê¹€ì¹˜ì°Œê°œ': ['ë¼ë©´ì‚¬ë¦¬'],
                'BBQ Platter': ['BBQ ê³ ê¸°ì¶”ê°€'],
                'ëª¨ë‘  ëˆìœ¡êµ¬ì´': ['ì‚¼ê²¹ì‚´ì¶”ê°€'],
                'íŒŒìŠ¤íƒ€': ['íŒŒìŠ¤íƒ€ë©´ ì¶”ê°€']
            },
            # ì—…ì¥ ê°„ ìƒê´€ê´€ê³„ (ë™ì‹œ ë°œìƒ ê°€ëŠ¥ì„± ë†’ìŒ)
            'cross_restaurant_correlations': {
                'ì£¼ë¥˜': ['ì£¼ë¥˜'],  # ë§¥ì£¼, ì†Œì£¼ ë“± ì£¼ë¥˜ë¼ë¦¬ ìƒê´€ê´€ê³„
                'ìŒë£Œ': ['ìŒë£Œ'],  # ìŒë£Œë¼ë¦¬ ìƒê´€ê´€ê³„
                'ë©”ì¸ë©”ë‰´': ['ì‚¬ì´ë“œë©”ë‰´']  # ë©”ì¸ë©”ë‰´ ì£¼ë¬¸ ì‹œ ì‚¬ì´ë“œë©”ë‰´ ê°€ëŠ¥ì„±
            }
        }

    def get_menu_category(self, menu_name):
        """ë©”ë‰´ëª…ìœ¼ë¡œë¶€í„° ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        for category, keywords in self.menu_categories.items():
            for keyword in keywords:
                if keyword in menu_name:
                    return category
        return 'ê¸°íƒ€'

    def get_restaurant_weight(self, restaurant_name):
        """ì—…ì¥ë³„ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        for rest_key, info in self.restaurant_info.items():
            if rest_key in restaurant_name:
                return info['weight']
        return 1.0


# ========================================
# 4. ê³ ë„í™”ëœ ë°ì´í„° ì²˜ë¦¬ê¸°
# ========================================

class AdvancedDataProcessor:
    """ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ ê³ ë„í™” ë°ì´í„° ì²˜ë¦¬"""

    def __init__(self):
        self.domain_engineer = DomainFeatureEngineer()
        self.kr_holidays = holidays.KR(years=range(2023, 2026))
        self.label_encoders = {}
        self.scalers = {}
        self.menu_stats = {}
        self.correlation_features = {}

    def load_data(self, train_path='./train/train.csv', test_dir='./test/'):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"""
        print_section("ë°ì´í„° ë¡œë“œ", "ğŸ“Š")

        # Train ë°ì´í„°
        self.train = pd.read_csv(train_path)
        print(f"âœ“ Train ë°ì´í„°: {self.train.shape}")
        print(f"âœ“ Train ì»¬ëŸ¼: {list(self.train.columns)}")

        # ì˜ì—…ì¥ëª…_ë©”ë‰´ëª… ë¶„ë¦¬
        self.train[['ì—…ì¥ëª…', 'ë©”ë‰´ëª…']] = self.train['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_', n=1, expand=True)

        # ë‚ ì§œ ì²˜ë¦¬
        if self.train['ì˜ì—…ì¼ì'].dtype == 'object':
            self.train['ì˜ì—…ì¼ì'] = pd.to_datetime(self.train['ì˜ì—…ì¼ì'])

        # Test ë°ì´í„°ë“¤
        test_files = sorted(glob.glob(os.path.join(test_dir, 'TEST_*.csv')))
        self.test_data = {}

        for file in test_files:
            test_name = os.path.basename(file).replace('.csv', '')
            df = pd.read_csv(file)
            print(f"âœ“ {test_name} ì»¬ëŸ¼: {list(df.columns)}")
            df[['ì—…ì¥ëª…', 'ë©”ë‰´ëª…']] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_', n=1, expand=True)

            if df['ì˜ì—…ì¼ì'].dtype == 'object':
                df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])

            self.test_data[test_name] = df
            print(f"âœ“ {test_name} ë°ì´í„°: {df.shape}")

        # Sample submission
        try:
            self.sample_submission = pd.read_csv('./sample_submission.csv')
            print(f"âœ“ Submission í˜•ì‹: {self.sample_submission.shape}")
            print(f"âœ“ Submission ì»¬ëŸ¼ ìˆ˜: {len(self.sample_submission.columns)}")
        except FileNotFoundError:
            print("âš ï¸ Sample submission íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.sample_submission = None
        except Exception as e:
            print(f"âš ï¸ Sample submission ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.sample_submission = None

        # ê¸°ë³¸ ì»¬ëŸ¼ ìˆœì„œ ì €ì¥ (sample_submissionì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„)
        if self.sample_submission is None:
            # Train ë°ì´í„°ì—ì„œ ë©”ë‰´ ìˆœì„œ ê°€ì ¸ì˜¤ê¸°
            menu_columns = ['ì˜ì—…ì¼ì'] + sorted(self.train['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique().tolist())
            print(f"âœ“ ê¸°ë³¸ ì»¬ëŸ¼ ìˆœì„œ ìƒì„±: {len(menu_columns)}ê°œ ì»¬ëŸ¼")
            # ì„ì‹œ sample_submission ìƒì„±
            temp_data = {col: [0] if col == 'ì˜ì—…ì¼ì' else [0] for col in menu_columns}
            temp_data['ì˜ì—…ì¼ì'] = ['TEST_00+1ì¼']
            self.sample_submission = pd.DataFrame(temp_data)

        return self.train, self.test_data

    def extract_datetime_features(self, df):
        """ê³ ë„í™”ëœ ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ"""
        df = df.copy()

        # ê¸°ë³¸ ë‚ ì§œ íŠ¹ì„±
        df['date'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['day'] = df['date'].dt.day
        df['dayofweek'] = df['date'].dt.dayofweek
        df['dayofyear'] = df['date'].dt.dayofyear
        df['week'] = df['date'].dt.isocalendar().week
        df['quarter'] = df['date'].dt.quarter

        # ì£¼ë§/í‰ì¼
        df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
        df['is_friday'] = (df['dayofweek'] == 4).astype(int)
        df['is_saturday'] = (df['dayofweek'] == 5).astype(int)
        df['is_sunday'] = (df['dayofweek'] == 6).astype(int)

        # ê³µíœ´ì¼
        df['is_holiday'] = df['date'].apply(lambda x: 1 if x in self.kr_holidays else 0)

        # ê³„ì ˆì„± - í”„ë¡œì íŠ¸ ì§€ì‹ ê¸°ë°˜
        def get_season_features(month):
            # ê²¨ìš¸: ìŠ¤í‚¤ ê³ ê°, ë´„ê°€ì„: í™”ë‹´ìˆ² ë°©ë¬¸ê°, ì—¬ë¦„: ê°€ì¡±ë‹¨ìœ„ ì²´ë¥˜í˜• ê´€ê´‘ê°
            if month in [12, 1, 2]:
                return 'winter', 1, 0, 0  # winter, is_ski_season, is_forest_season, is_family_season
            elif month in [3, 4, 5, 9, 10, 11]:
                return 'spring_fall', 0, 1, 0
            else:  # 6, 7, 8
                return 'summer', 0, 0, 1

        season_info = df['month'].apply(get_season_features)
        df['season'] = [x[0] for x in season_info]
        df['is_ski_season'] = [x[1] for x in season_info]
        df['is_forest_season'] = [x[2] for x in season_info]
        df['is_family_season'] = [x[3] for x in season_info]

        # ì—°ë§ì—°ì‹œ íŠ¹ë³„ ê¸°ê°„
        df['is_year_end'] = ((df['month'] == 12) & (df['day'] >= 20)).astype(int)
        df['is_new_year'] = ((df['month'] == 1) & (df['day'] <= 10)).astype(int)

        # ì£¼ê¸°ì  íŠ¹ì„± (sin/cos ë³€í™˜)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
        df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)
        df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)

        return df

    def extract_menu_features(self, df):
        """ë©”ë‰´ íŠ¹ì„± ì¶”ì¶œ - ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜"""
        df = df.copy()

        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬
        df['menu_category'] = df['ë©”ë‰´ëª…'].apply(self.domain_engineer.get_menu_category)

        # ì˜¨ë„ ê¸°ë°˜ íŠ¹ì„± (HOT/ICE)
        df['is_hot_menu'] = df['ë©”ë‰´ëª…'].str.contains('HOT', case=False, na=False).astype(int)
        df['is_ice_menu'] = df['ë©”ë‰´ëª…'].str.contains('ICE', case=False, na=False).astype(int)

        # ì—…ì¥ë³„ íŠ¹ì„±
        df['restaurant_type'] = df['ì—…ì¥ëª…'].apply(lambda x: self._get_restaurant_type(x))
        df['restaurant_weight'] = df['ì—…ì¥ëª…'].apply(self.domain_engineer.get_restaurant_weight)

        # ê°€ê²©ëŒ€ ì¶”ì • (ë©”ë‰´ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ)
        df['estimated_price'] = df['ë©”ë‰´ëª…'].str.extract(r'(\d+)').astype(float).fillna(0)

        # ë‹¨ì²´ ë©”ë‰´ ì—¬ë¶€
        df['is_group_menu'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´', na=False).astype(int)

        # ì •ì‹/íŒ¨í‚¤ì§€ ë©”ë‰´ ì—¬ë¶€
        df['is_set_menu'] = df['ë©”ë‰´ëª…'].str.contains('ì •ì‹|íŒ¨í‚¤ì§€', na=False).astype(int)

        return df

    def _get_restaurant_type(self, restaurant_name):
        """ì—…ì¥ íƒ€ì… ë°˜í™˜"""
        for rest_key, info in self.domain_engineer.restaurant_info.items():
            if rest_key in restaurant_name:
                return info['type']
        return 'other'

    def extract_lag_features_safe(self, df, is_train=True):
        """ì•ˆì „í•œ ì‹œê³„ì—´ ì§€ì—° íŠ¹ì„± ì¶”ì¶œ"""
        if not is_train or 'ë§¤ì¶œìˆ˜ëŸ‰' not in df.columns:
            return df

        df = df.copy()
        df = df.sort_values(['ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'date'])

        print("ì§€ì—° íŠ¹ì„± ì¶”ì¶œ ì¤‘...")

        # ë©”ë‰´ë³„ë¡œ ë”°ë¡œ ì²˜ë¦¬
        all_dfs = []
        for menu in tqdm(df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique(), desc="ë©”ë‰´ë³„ ì§€ì—° íŠ¹ì„±"):
            menu_df = df[df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu].copy()
            menu_df = menu_df.sort_values('date')

            # ê¸°ë³¸ ì§€ì—° íŠ¹ì„±
            for lag in [1, 2, 3, 7, 14, 21, 28]:
                menu_df[f'sales_lag_{lag}'] = menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].shift(lag)

            # ì´ë™í‰ê·  - ë” ì•ˆì „í•œ ë°©ë²•
            for window in [3, 7, 14, 28]:
                menu_df[f'sales_ma_{window}'] = menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(
                    window=window, min_periods=1
                ).mean()

            # ì´ë™í‘œì¤€í¸ì°¨
            for window in [7, 14, 28]:
                menu_df[f'sales_std_{window}'] = menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(
                    window=window, min_periods=1
                ).std().fillna(0)

            all_dfs.append(menu_df)

        # ëª¨ë“  ë©”ë‰´ ë°ì´í„° í•©ì¹˜ê¸°
        result_df = pd.concat(all_dfs, ignore_index=True)

        # ìš”ì¼ë³„/ì›”ë³„/ê³„ì ˆë³„ í‰ê·  ì¶”ê°€
        print("í†µê³„ì  íŠ¹ì„± ì¶”ê°€ ì¤‘...")

        # ìš”ì¼ë³„ í‰ê· 
        dayofweek_stats = result_df.groupby(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'dayofweek'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
        dayofweek_stats.columns = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'dayofweek', 'sales_dayofweek_mean']
        result_df = result_df.merge(dayofweek_stats, on=['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'dayofweek'], how='left')

        # ì›”ë³„ í‰ê· 
        month_stats = result_df.groupby(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'month'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
        month_stats.columns = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'month', 'sales_month_mean']
        result_df = result_df.merge(month_stats, on=['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'month'], how='left')

        # ê³„ì ˆë³„ í‰ê· 
        season_stats = result_df.groupby(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'season'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
        season_stats.columns = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'season', 'sales_season_mean']
        result_df = result_df.merge(season_stats, on=['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'season'], how='left')

        return result_df

    def extract_correlation_features(self, df, is_train=True):
        """ë©”ë‰´ ê°„ ìƒê´€ê´€ê³„ íŠ¹ì„± ì¶”ì¶œ"""
        if not is_train or 'ë§¤ì¶œìˆ˜ëŸ‰' not in df.columns:
            return df

        df = df.copy()

        print("ìƒê´€ê´€ê³„ íŠ¹ì„± ì¶”ì¶œ ì¤‘...")

        # ê°™ì€ ì—…ì¥ ë‚´ ë‹¤ë¥¸ ë©”ë‰´ë“¤ì˜ ë§¤ì¶œ í•©ê³„
        restaurant_daily_sales = df.groupby(['ì—…ì¥ëª…', 'date'])['ë§¤ì¶œìˆ˜ëŸ‰'].sum().reset_index()
        restaurant_daily_sales.columns = ['ì—…ì¥ëª…', 'date', 'restaurant_total_sales']
        df = df.merge(restaurant_daily_sales, on=['ì—…ì¥ëª…', 'date'], how='left')

        # ê°™ì€ ì¹´í…Œê³ ë¦¬ ë©”ë‰´ë“¤ì˜ ë§¤ì¶œ í•©ê³„
        category_daily_sales = df.groupby(['menu_category', 'date'])['ë§¤ì¶œìˆ˜ëŸ‰'].sum().reset_index()
        category_daily_sales.columns = ['menu_category', 'date', 'category_total_sales']
        df = df.merge(category_daily_sales, on=['menu_category', 'date'], how='left')

        # ì£¼ë¥˜ ì´ ë§¤ì¶œ (ì—…ì¥ ê°„ ìƒê´€ê´€ê³„)
        alcohol_sales = df[df['menu_category'] == 'ì£¼ë¥˜'].groupby('date')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().reset_index()
        alcohol_sales.columns = ['date', 'total_alcohol_sales']
        df = df.merge(alcohol_sales, on='date', how='left')
        df['total_alcohol_sales'] = df['total_alcohol_sales'].fillna(0)

        # ë©”ì¸ë©”ë‰´ ì´ ë§¤ì¶œ
        main_sales = df[df['menu_category'] == 'ë©”ì¸ë©”ë‰´'].groupby('date')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().reset_index()
        main_sales.columns = ['date', 'total_main_sales']
        df = df.merge(main_sales, on='date', how='left')
        df['total_main_sales'] = df['total_main_sales'].fillna(0)

        return df

    def calculate_menu_statistics(self, df):
        """ë©”ë‰´ë³„ í†µê³„ ê³„ì‚° ë° ì €ì¥"""
        print_section("ë©”ë‰´ë³„ í†µê³„ ê³„ì‚°", "ğŸ“ˆ")

        for menu in df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
            menu_data = df[df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu]['ë§¤ì¶œìˆ˜ëŸ‰']

            weekend_data = df[(df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu) & (df['is_weekend'] == 1)]['ë§¤ì¶œìˆ˜ëŸ‰']
            weekday_data = df[(df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu) & (df['is_weekend'] == 0)]['ë§¤ì¶œìˆ˜ëŸ‰']

            self.menu_stats[menu] = {
                'mean': menu_data.mean(),
                'std': menu_data.std(),
                'min': menu_data.min(),
                'max': menu_data.max(),
                'q25': menu_data.quantile(0.25),
                'q75': menu_data.quantile(0.75),
                'zero_ratio': (menu_data == 0).mean(),
                'weekend_mean': weekend_data.mean() if len(weekend_data) > 0 else menu_data.mean(),
                'weekday_mean': weekday_data.mean() if len(weekday_data) > 0 else menu_data.mean(),
            }

        print(f"âœ“ {len(self.menu_stats)}ê°œ ë©”ë‰´ì˜ í†µê³„ ì •ë³´ ê³„ì‚° ì™„ë£Œ")

    def prepare_features(self, df, is_train=True):
        """ì „ì²´ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸"""
        print_section(f"{'Train' if is_train else 'Test'} ë°ì´í„° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§", "ğŸ”§")

        # 1. ì‹œê°„ íŠ¹ì„±
        df = self.extract_datetime_features(df)
        print("âœ“ ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 2. ë©”ë‰´ íŠ¹ì„±
        df = self.extract_menu_features(df)
        print("âœ“ ë©”ë‰´ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 3. ì§€ì—° íŠ¹ì„± (Trainë§Œ) - ì•ˆì „í•œ ë°©ë²• ì‚¬ìš©
        if is_train:
            df = self.extract_lag_features_safe(df, is_train=True)
            print("âœ“ ì‹œê³„ì—´ ì§€ì—° íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 4. ìƒê´€ê´€ê³„ íŠ¹ì„± (Trainë§Œ)
        if is_train:
            df = self.extract_correlation_features(df, is_train=True)
            print("âœ“ ë©”ë‰´ ê°„ ìƒê´€ê´€ê³„ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 5. ë©”ë‰´ í†µê³„ (Trainë§Œ)
        if is_train:
            self.calculate_menu_statistics(df)

        # 6. ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        cat_columns = ['ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'menu_category', 'season', 'restaurant_type']
        for col in cat_columns:
            if col in df.columns:
                if col not in self.label_encoders:
                    self.label_encoders[col] = LabelEncoder()
                    unique_values = df[col].unique().tolist()
                    self.label_encoders[col].fit(unique_values + ['UNKNOWN'])

                df[f'{col}_encoded'] = df[col].apply(
                    lambda x: self.label_encoders[col].transform([x])[0]
                    if x in self.label_encoders[col].classes_
                    else self.label_encoders[col].transform(['UNKNOWN'])[0]
                )

        print("âœ“ ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© ì™„ë£Œ")
        print(f"âœ“ ìµœì¢… íŠ¹ì„± ê°œìˆ˜: {df.shape[1]}")

        return df


# ========================================
# 5. ê³ ë„í™”ëœ ML ëª¨ë¸
# ========================================

class AdvancedMLModel:
    """ê³ ë„í™”ëœ ì•™ìƒë¸” ML ëª¨ë¸"""

    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.best_features = {}

    def create_model_ensemble(self):
        """ê°•í™”ëœ ì•™ìƒë¸” ëª¨ë¸ ìƒì„±"""
        models = {
            'xgboost': xgb.XGBRegressor(
                n_estimators=2000,
                max_depth=8,
                learning_rate=0.02,
                subsample=0.8,
                colsample_bytree=0.8,
                min_child_weight=5,
                gamma=0.1,
                reg_alpha=0.1,
                reg_lambda=1.5,
                random_state=42,
                n_jobs=-1,
                objective='reg:squarederror',
                verbosity=0
            ),
            'lightgbm': lgb.LGBMRegressor(
                n_estimators=2000,
                max_depth=8,
                learning_rate=0.02,
                num_leaves=64,
                min_child_samples=30,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=1.5,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            ),
            'catboost': CatBoostRegressor(
                iterations=2000,
                depth=6,
                learning_rate=0.02,
                l2_leaf_reg=5,
                random_seed=42,
                verbose=False,
                early_stopping_rounds=100
            ),
            'random_forest': RandomForestRegressor(
                n_estimators=500,
                max_depth=20,
                min_samples_split=15,
                min_samples_leaf=8,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1
            ),
            'extra_trees': ExtraTreesRegressor(
                n_estimators=500,
                max_depth=20,
                min_samples_split=15,
                min_samples_leaf=8,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1
            )
        }
        return models

    def train_models(self, X_train, y_train, X_val, y_val, model_name="default", weights=None):
        """ëª¨ë¸ í•™ìŠµ"""
        print_section(f"{model_name} ëª¨ë¸ í•™ìŠµ", "ğŸš€")

        start_time = time.time()
        models = self.create_model_ensemble()
        results = {}

        # ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ë³€í™˜
        print(f"í•™ìŠµ ë°ì´í„° í˜•íƒœ: {X_train.shape}")
        print(f"ë°ì´í„° íƒ€ì…: {X_train.dtypes.value_counts()}")

        # ë¬¸ìì—´ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        string_cols = X_train.select_dtypes(include=['object']).columns
        if len(string_cols) > 0:
            print(f"âš ï¸ ë¬¸ìì—´ ì»¬ëŸ¼ ë°œê²¬: {list(string_cols)}")
            # ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°
            X_train = X_train.select_dtypes(exclude=['object'])
            X_val = X_val.select_dtypes(exclude=['object'])
            print(f"ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±° í›„ í˜•íƒœ: {X_train.shape}")

        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
        X_train = X_train.astype('float32')
        X_val = X_val.astype('float32')

        # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
        X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)
        X_val = X_val.replace([np.inf, -np.inf], np.nan).fillna(0)

        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)

        self.scalers[model_name] = scaler

        for name, model in models.items():
            print(f"\nâ†’ {name} í•™ìŠµ ì¤‘...", end=" ")
            model_start = time.time()

            try:
                # ê°€ì¤‘ì¹˜ ì ìš© í•™ìŠµ
                if weights is not None and hasattr(model, 'fit'):
                    try:
                        model.fit(X_train_scaled, y_train, sample_weight=weights)
                    except:
                        model.fit(X_train_scaled, y_train)
                else:
                    model.fit(X_train_scaled, y_train)

                # ì˜ˆì¸¡
                pred = model.predict(X_val_scaled)
                pred = np.maximum(pred, 0)  # ìŒìˆ˜ ì œê±°

                # ì„±ëŠ¥ ê³„ì‚°
                score = smape(y_val, pred)

                results[name] = {
                    'model': model,
                    'pred': pred,
                    'smape': score
                }

                print(f"ì™„ë£Œ ({time.time() - model_start:.1f}ì´ˆ, sMAPE: {score:.3f})")

            except Exception as e:
                print(f"ì‹¤íŒ¨ ({str(e)})")
                continue

        print(f"\nâœ“ ì´ í•™ìŠµ ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ")
        print(f"âœ“ ì„±ê³µí•œ ëª¨ë¸: {len(results)}ê°œ")

        return results

    def weighted_ensemble_predict(self, models, X_test, scaler, weights=None):
        """ê°€ì¤‘ ì•™ìƒë¸” ì˜ˆì¸¡"""
        # ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ë³€í™˜
        if hasattr(X_test, 'select_dtypes'):
            # ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°
            string_cols = X_test.select_dtypes(include=['object']).columns
            if len(string_cols) > 0:
                X_test = X_test.select_dtypes(exclude=['object'])

            # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
            X_test = X_test.astype('float32')

            # ë¬´í•œëŒ€ ê°’ ì²˜ë¦¬
            X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)

        X_test_scaled = scaler.transform(X_test)
        predictions = []

        if weights is None:
            # sMAPE ê¸°ë°˜ ìë™ ê°€ì¤‘ì¹˜
            scores = [m['smape'] for m in models.values() if 'smape' in m]
            if scores:
                inv_scores = [1 / (s + 1) for s in scores]
                total = sum(inv_scores)
                weights = {name: inv_scores[i] / total for i, name in enumerate(models.keys())}
            else:
                weights = {name: 1 / len(models) for name in models.keys()}

        for name, model_info in models.items():
            if 'model' in model_info:
                pred = model_info['model'].predict(X_test_scaled)
                pred = np.maximum(pred, 0)
                predictions.append(pred * weights.get(name, 0))

        if predictions:
            return np.sum(predictions, axis=0)
        else:
            return np.zeros(len(X_test))


# ========================================
# 6. ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ========================================

class AdvancedPipeline:
    """ê³ ë„í™”ëœ ì „ì²´ íŒŒì´í”„ë¼ì¸"""

    def __init__(self):
        self.processor = AdvancedDataProcessor()
        self.model = AdvancedMLModel()
        self.menu_models = {}
        self.global_models = {}

    def analyze_data(self, df):
        """ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”"""
        print_section("ë°ì´í„° ë¶„ì„", "ğŸ“Š")

        # ê¸°ë³¸ í†µê³„
        print("ğŸ“ˆ ë§¤ì¶œìˆ˜ëŸ‰ ê¸°ë³¸ í†µê³„:")
        print(df['ë§¤ì¶œìˆ˜ëŸ‰'].describe())

        # ì—…ì¥ë³„ ë§¤ì¶œ ë¶„ì„
        restaurant_sales = df.groupby('ì—…ì¥ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'count'])
        print(f"\nğŸª ì—…ì¥ë³„ ë§¤ì¶œ í˜„í™©:")
        print(restaurant_sales.sort_values('sum', ascending=False))

        # ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¶„ì„
        if 'menu_category' in df.columns:
            category_sales = df.groupby('menu_category')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'count'])
            print(f"\nğŸ½ï¸ ë©”ë‰´ ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ í˜„í™©:")
            print(category_sales.sort_values('sum', ascending=False))

        # ê³„ì ˆì„± ë¶„ì„
        if 'season' in df.columns:
            seasonal_sales = df.groupby('season')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean'])
            print(f"\nğŸŒ¸ ê³„ì ˆë³„ ë§¤ì¶œ í˜„í™©:")
            print(seasonal_sales)

        # ìš”ì¼ë³„ ë¶„ì„
        if 'dayofweek' in df.columns:
            dow_sales = df.groupby('dayofweek')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean'])
            dow_sales.index = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
            print(f"\nğŸ“… ìš”ì¼ë³„ ë§¤ì¶œ í˜„í™©:")
            print(dow_sales)

    def create_future_features(self, last_row, pred_date, feature_cols):
        """ë¯¸ë˜ ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„± ìƒì„±"""
        future_data = last_row.copy()

        # ë‚ ì§œ ê´€ë ¨ íŠ¹ì„± ì—…ë°ì´íŠ¸
        future_data['date'] = pred_date
        future_data['year'] = pred_date.year
        future_data['month'] = pred_date.month
        future_data['day'] = pred_date.day
        future_data['dayofweek'] = pred_date.dayofweek
        future_data['dayofyear'] = pred_date.dayofyear
        future_data['week'] = pred_date.isocalendar().week
        future_data['quarter'] = pred_date.quarter

        # ì£¼ë§/í‰ì¼
        future_data['is_weekend'] = 1 if pred_date.dayofweek >= 5 else 0
        future_data['is_friday'] = 1 if pred_date.dayofweek == 4 else 0
        future_data['is_saturday'] = 1 if pred_date.dayofweek == 5 else 0
        future_data['is_sunday'] = 1 if pred_date.dayofweek == 6 else 0

        # ê³µíœ´ì¼
        future_data['is_holiday'] = 1 if pred_date in self.processor.kr_holidays else 0

        # ê³„ì ˆì„±
        month = pred_date.month
        if month in [12, 1, 2]:
            future_data['season'] = 'winter'
            future_data['is_ski_season'] = 1
            future_data['is_forest_season'] = 0
            future_data['is_family_season'] = 0
        elif month in [3, 4, 5, 9, 10, 11]:
            future_data['season'] = 'spring_fall'
            future_data['is_ski_season'] = 0
            future_data['is_forest_season'] = 1
            future_data['is_family_season'] = 0
        else:
            future_data['season'] = 'summer'
            future_data['is_ski_season'] = 0
            future_data['is_forest_season'] = 0
            future_data['is_family_season'] = 1

        # ì—°ë§ì—°ì‹œ
        future_data['is_year_end'] = 1 if (month == 12 and pred_date.day >= 20) else 0
        future_data['is_new_year'] = 1 if (month == 1 and pred_date.day <= 10) else 0

        # ì£¼ê¸°ì  íŠ¹ì„±
        future_data['month_sin'] = np.sin(2 * np.pi * month / 12)
        future_data['month_cos'] = np.cos(2 * np.pi * month / 12)
        future_data['day_sin'] = np.sin(2 * np.pi * pred_date.day / 31)
        future_data['day_cos'] = np.cos(2 * np.pi * pred_date.day / 31)
        future_data['dayofweek_sin'] = np.sin(2 * np.pi * pred_date.dayofweek / 7)
        future_data['dayofweek_cos'] = np.cos(2 * np.pi * pred_date.dayofweek / 7)

        # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        for col in ['season']:
            if f'{col}_encoded' in feature_cols and col in self.processor.label_encoders:
                future_data[f'{col}_encoded'] = self.processor.label_encoders[col].transform([future_data[col]])[0]

        return future_data

    def create_submission(self, predictions):
        """ì œì¶œ íŒŒì¼ ìƒì„±"""
        print_section("ì œì¶œ íŒŒì¼ ìƒì„±", "ğŸ“")

        pred_df = pd.DataFrame(predictions)
        print(f"ì›ë³¸ ì˜ˆì¸¡ ë°ì´í„° í˜•íƒœ: {pred_df.shape}")
        print(f"ì»¬ëŸ¼: {list(pred_df.columns)}")

        # ìŒìˆ˜ ì œê±° ë° ì •ìˆ˜ ë³€í™˜
        pred_df['ë§¤ì¶œìˆ˜ëŸ‰'] = pred_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0).round().astype(int)

        # Long formatì„ Wide formatìœ¼ë¡œ ë³€í™˜
        print("Long formatì„ Wide formatìœ¼ë¡œ ë³€í™˜ ì¤‘...")

        # pivot_table ì‚¬ìš©í•˜ì—¬ ë³€í™˜
        wide_df = pred_df.pivot_table(
            index='ì˜ì—…ì¼ì',
            columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…',
            values='ë§¤ì¶œìˆ˜ëŸ‰',
            fill_value=0
        ).reset_index()

        print(f"Wide format í˜•íƒœ: {wide_df.shape}")

        # sample_submissionì´ ìˆëŠ” ê²½ìš° ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        if hasattr(self.processor, 'sample_submission') and self.processor.sample_submission is not None:
            try:
                # sample_submissionì˜ ì»¬ëŸ¼ ìˆœì„œëŒ€ë¡œ ì •ë ¬
                missing_cols = set(self.processor.sample_submission.columns) - set(wide_df.columns)
                if missing_cols:
                    print(f"âš ï¸ ëˆ„ë½ëœ ì»¬ëŸ¼ {len(missing_cols)}ê°œë¥¼ 0ìœ¼ë¡œ ì¶”ê°€")
                    for col in missing_cols:
                        wide_df[col] = 0

                # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
                wide_df = wide_df[self.processor.sample_submission.columns]
                print("âœ“ Sample submission í˜•ì‹ì— ë§ì¶° ì»¬ëŸ¼ ìˆœì„œ ì¡°ì • ì™„ë£Œ")

            except Exception as e:
                print(f"âš ï¸ Sample submission í˜•ì‹ ë§ì¶”ê¸° ì‹¤íŒ¨: {e}")
                print("ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
        else:
            print("âš ï¸ Sample submission íŒŒì¼ì´ ì—†ì–´ ê¸°ë³¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥")

        # ì €ì¥
        output_file = f'advanced_submission_{datetime.now().strftime("%m%d_%H%M")}.csv'
        wide_df.to_csv(output_file, index=False, encoding='utf-8-sig')

        print(f"âœ“ ì œì¶œ íŒŒì¼ ì €ì¥: {output_file}")
        print(f"âœ“ ì˜ˆì¸¡ ë‚ ì§œ ìˆ˜: {len(wide_df)}")
        print(f"âœ“ ë©”ë‰´ ìˆ˜: {len(wide_df.columns) - 1}")  # ì˜ì—…ì¼ì ì œì™¸
        print(f"âœ“ ì´ ì˜ˆì¸¡ê°’ í•©ê³„: {wide_df.select_dtypes(include=[np.number]).sum().sum()}")

        return wide_df

    def calculate_test_smape(self, predictions, test_data):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ sMAPE ê³„ì‚° (ê²€ì¦ìš©)"""
        print_section("í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ê²€ì¦", "ğŸ¯")

        # ì‹¤ì œ ê°’ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ê³„ì‚°
        total_smape = 0
        valid_predictions = 0

        for test_name, test_df in test_data.items():
            if 'ë§¤ì¶œìˆ˜ëŸ‰' in test_df.columns:
                # í•´ë‹¹ í…ŒìŠ¤íŠ¸ì˜ ì˜ˆì¸¡ê°’ í•„í„°ë§
                test_preds = [p for p in predictions if test_name in p['ì˜ì—…ì¼ì']]

                if test_preds:
                    pred_df = pd.DataFrame(test_preds)

                    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ë§¤ì¹­
                    merged = test_df.merge(pred_df, on='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', how='inner')

                    if len(merged) > 0:
                        smape_score = smape(merged['ë§¤ì¶œìˆ˜ëŸ‰_x'], merged['ë§¤ì¶œìˆ˜ëŸ‰_y'])
                        print(f"âœ“ {test_name} sMAPE: {smape_score:.3f}")
                        total_smape += smape_score
                        valid_predictions += 1

        if valid_predictions > 0:
            avg_smape = total_smape / valid_predictions
            print(f"\nğŸ¯ í‰ê·  sMAPE: {avg_smape:.3f}")
            return avg_smape
        else:
            print("âš ï¸ ì‹¤ì œê°’ì„ í¬í•¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ sMAPE ê³„ì‚° ë¶ˆê°€")
            return None

    def run(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print_section("ê³ ë„í™”ëœ ê³¤ì§€ì•” ë¦¬ì¡°íŠ¸ ìˆ˜ìš”ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œì‘", "ğŸš€")

        total_start = time.time()

        # 1. ë°ì´í„° ë¡œë“œ
        train, test_data = self.processor.load_data()

        # 2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
        train_fe = self.processor.prepare_features(train, is_train=True)

        # 3. ë°ì´í„° ë¶„ì„
        self.analyze_data(train_fe)

        # 4. íŠ¹ì„± ì„ íƒ - ë¬¸ìì—´ ì»¬ëŸ¼ ì œì™¸
        exclude_cols = [
            'ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰', 'date', 'ì—…ì¥ëª…', 'ë©”ë‰´ëª…',
            'season', 'menu_category', 'restaurant_type'  # ë¬¸ìì—´ ì»¬ëŸ¼ë“¤ ì œì™¸
        ]

        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        feature_cols = []
        for col in train_fe.columns:
            if col not in exclude_cols:
                # ìˆ«ìí˜• ë°ì´í„°ì¸ì§€ í™•ì¸
                if train_fe[col].dtype in ['int64', 'float64', 'int32', 'float32', 'bool']:
                    feature_cols.append(col)
                elif col.endswith('_encoded'):  # ì¸ì½”ë”©ëœ ì»¬ëŸ¼ì€ í¬í•¨
                    feature_cols.append(col)

        print(f"\nğŸ“Š ì‚¬ìš©í•  íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}")
        print(f"ğŸ“Š íŠ¹ì„± ëª©ë¡ (ì²˜ìŒ 20ê°œ): {feature_cols[:20]}")

        target_col = 'ë§¤ì¶œìˆ˜ëŸ‰'

        # 5. ì‹œê³„ì—´ ë¶„í• 
        train_fe = train_fe.sort_values('date')
        split_date = train_fe['date'].max() - pd.Timedelta(days=45)

        train_set = train_fe[train_fe['date'] < split_date]
        val_set = train_fe[train_fe['date'] >= split_date]

        X_train = train_set[feature_cols].fillna(0)
        y_train = train_set[target_col]
        X_val = val_set[feature_cols].fillna(0)
        y_val = val_set[target_col]

        # ì—…ì¥ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚°
        train_weights = train_set['restaurant_weight'].values

        print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}, ê²€ì¦ ë°ì´í„°: {X_val.shape}")

        # 6. ì „ì²´ ëª¨ë¸ í•™ìŠµ
        print_section("ì „ì²´ í†µí•© ëª¨ë¸ í•™ìŠµ", "ğŸ¯")
        self.global_models = self.model.train_models(
            X_train, y_train, X_val, y_val, "global", weights=train_weights
        )

        # 7. ì£¼ìš” ë©”ë‰´ë³„ ê°œë³„ ëª¨ë¸ í•™ìŠµ
        print_section("ì£¼ìš” ë©”ë‰´ë³„ ê°œë³„ ëª¨ë¸ í•™ìŠµ", "ğŸ¯")

        # ë‹´í•˜ì™€ ë¯¸ë¼ì‹œì•„ ë©”ë‰´ ìš°ì„  + ë§¤ì¶œ ìƒìœ„ ë©”ë‰´
        high_weight_menus = train_fe[
            (train_fe['ì—…ì¥ëª…'].str.contains('ë‹´í•˜|ë¯¸ë¼ì‹œì•„', na=False)) |
            (train_fe.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].transform('sum') > train_fe['ë§¤ì¶œìˆ˜ëŸ‰'].sum() * 0.005)
            ]['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()

        print(f"ê°œë³„ ëª¨ë¸ í•™ìŠµ ëŒ€ìƒ: {len(high_weight_menus)}ê°œ ë©”ë‰´")

        for menu in tqdm(high_weight_menus, desc="ê°œë³„ ëª¨ë¸ í•™ìŠµ"):
            menu_data = train_fe[train_fe['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu]

            if len(menu_data) < 100:  # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ìŠ¤í‚µ
                continue

            menu_train = menu_data[menu_data['date'] < split_date]
            menu_val = menu_data[menu_data['date'] >= split_date]

            if len(menu_val) < 5:
                continue

            X_train_menu = menu_train[feature_cols].fillna(0)
            y_train_menu = menu_train[target_col]
            X_val_menu = menu_val[feature_cols].fillna(0)
            y_val_menu = menu_val[target_col]

            menu_weights = menu_train['restaurant_weight'].values

            # ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ
            menu_models = self.model.train_models(
                X_train_menu, y_train_menu,
                X_val_menu, y_val_menu,
                menu, weights=menu_weights
            )

            self.menu_models[menu] = menu_models

        # 8. ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ
        print_section("ìµœì¢… ëª¨ë¸ ì¬í•™ìŠµ", "ğŸ¯")

        X_full = train_fe[feature_cols].fillna(0)
        y_full = train_fe[target_col]
        full_weights = train_fe['restaurant_weight'].values

        # ë§ˆì§€ë§‰ 10% ê²€ì¦ìš©
        val_size = max(int(len(X_full) * 0.1), 1000)

        final_models = self.model.train_models(
            X_full[:-val_size], y_full.iloc[:-val_size],
            X_full[-val_size:], y_full.iloc[-val_size:],
            "final", weights=full_weights[:-val_size]
        )

        # 9. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        print_section("í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡", "ğŸ“")

        all_predictions = []

        for test_name, test_df in test_data.items():
            print(f"\nâ†’ {test_name} ì˜ˆì¸¡ ì¤‘...")

            # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (ê°„ë‹¨ ë²„ì „)
            test_fe = test_df.copy()
            test_fe = self.processor.extract_datetime_features(test_fe)
            test_fe = self.processor.extract_menu_features(test_fe)

            # ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
            cat_columns = ['ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'menu_category', 'season', 'restaurant_type']
            for col in cat_columns:
                if col in test_fe.columns and col in self.processor.label_encoders:
                    test_fe[f'{col}_encoded'] = test_fe[col].apply(
                        lambda x: self.processor.label_encoders[col].transform([x])[0]
                        if x in self.processor.label_encoders[col].classes_
                        else self.processor.label_encoders[col].transform(['UNKNOWN'])[0]
                    )

            # ë§ˆì§€ë§‰ ë‚ ì§œ
            last_date = test_df['ì˜ì—…ì¼ì'].max()
            if not isinstance(last_date, pd.Timestamp):
                last_date = pd.to_datetime(last_date)

            # 7ì¼ê°„ ì˜ˆì¸¡
            for day_ahead in range(1, 8):
                pred_date = last_date + timedelta(days=day_ahead)

                for menu in test_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
                    # í•´ë‹¹ ë©”ë‰´ì˜ ë§ˆì§€ë§‰ ë°ì´í„° í–‰
                    menu_last_row = test_fe[test_fe['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu].iloc[-1].copy()

                    # ë¯¸ë˜ íŠ¹ì„± ìƒì„±
                    future_features = self.create_future_features(
                        menu_last_row, pred_date, feature_cols
                    )

                    # ëˆ„ë½ëœ íŠ¹ì„± ì²˜ë¦¬
                    for col in feature_cols:
                        if col not in future_features.index:
                            future_features[col] = 0

                    # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ê³  ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°
                    future_df = pd.DataFrame([future_features[feature_cols]]).fillna(0)

                    # ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±° ë° ìˆ«ìí˜• ë³€í™˜
                    string_cols = future_df.select_dtypes(include=['object']).columns
                    if len(string_cols) > 0:
                        future_df = future_df.select_dtypes(exclude=['object'])

                    future_df = future_df.astype('float32')
                    future_df = future_df.replace([np.inf, -np.inf], np.nan).fillna(0)

                    # ì˜ˆì¸¡
                    if menu in self.menu_models and len(self.menu_models[menu]) > 0:
                        # ë©”ë‰´ë³„ ëª¨ë¸ ì‚¬ìš©
                        pred_value = self.model.weighted_ensemble_predict(
                            self.menu_models[menu],
                            future_df,
                            self.model.scalers[menu]
                        )[0]
                    else:
                        # ì „ì²´ ëª¨ë¸ ì‚¬ìš©
                        pred_value = self.model.weighted_ensemble_predict(
                            final_models,
                            future_df,
                            self.model.scalers["final"]
                        )[0]

                    # í›„ì²˜ë¦¬
                    if menu in self.processor.menu_stats:
                        stats = self.processor.menu_stats[menu]

                        # ê·¹ë‹¨ê°’ ì œí•œ
                        pred_value = np.clip(pred_value, 0, stats['max'] * 2.0)

                        # ìš”ì¼ë³„ ì¡°ì •
                        if pred_date.dayofweek >= 5:  # ì£¼ë§
                            weekend_ratio = stats.get('weekend_mean', stats['mean']) / (stats['mean'] + 1e-6)
                            pred_value *= max(weekend_ratio, 0.5)

                        # ê³µíœ´ì¼ ì¡°ì •
                        if pred_date in self.processor.kr_holidays:
                            pred_value *= 1.3

                        # ê³„ì ˆë³„ ì¡°ì •
                        month = pred_date.month
                        restaurant = menu.split('_')[0]

                        if 'ëŠí‹°ë‚˜ë¬´' in restaurant and month in [6, 7, 8]:  # ì—¬ë¦„ BBQ
                            pred_value *= 1.2
                        elif 'í™”ë‹´ìˆ²' in restaurant and month in [3, 4, 5, 9, 10, 11]:  # ë´„ê°€ì„ í™”ë‹´ìˆ²
                            pred_value *= 1.2
                        elif ('ì¹´í˜í…Œë¦¬ì•„' in restaurant or 'í¬ë ˆìŠ¤íŠ¸ë¦¿' in restaurant) and month in [12, 1, 2]:  # ê²¨ìš¸ ìŠ¤í‚¤
                            pred_value *= 1.2

                        # HOT/ICE ë©”ë‰´ ê³„ì ˆë³„ ì¡°ì •
                        if 'HOT' in menu and month in [12, 1, 2]:
                            pred_value *= 1.3
                        elif 'ICE' in menu and month in [6, 7, 8]:
                            pred_value *= 1.3
                        elif 'ICE' in menu and month in [12, 1, 2]:
                            pred_value *= 0.7

                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{test_name}+{day_ahead}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu,
                        'ë§¤ì¶œìˆ˜ëŸ‰': max(0, int(round(pred_value)))
                    })

        # 10. ì œì¶œ íŒŒì¼ ìƒì„±
        submission_df = self.create_submission(all_predictions)

        # 11. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ê³„ì‚° (ê°€ëŠ¥í•œ ê²½ìš°)
        test_smape = self.calculate_test_smape(all_predictions, test_data)

        # 12. ìµœì¢… ê²°ê³¼ ìš”ì•½
        total_time = time.time() - total_start
        print_section("íŒŒì´í”„ë¼ì¸ ì™„ë£Œ", "âœ…")
        print(f"âœ… ì´ ì‹¤í–‰ ì‹œê°„: {total_time / 60:.1f}ë¶„")
        print(f"âœ… í•™ìŠµëœ ì „ì²´ ëª¨ë¸: {len(self.global_models)}ê°œ")
        print(f"âœ… í•™ìŠµëœ ê°œë³„ ëª¨ë¸: {len(self.menu_models)}ê°œ")
        print(f"âœ… ì´ ì˜ˆì¸¡ ê±´ìˆ˜: {len(all_predictions)}ê°œ")
        if test_smape:
            print(f"âœ… ì˜ˆìƒ sMAPE: {test_smape:.3f}")

        return submission_df


# ========================================
# 7. ì‹¤í–‰
# ========================================

if __name__ == "__main__":
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = AdvancedPipeline()
    result = pipeline.run()

    print("\nğŸ¯ ê³ ë„í™”ëœ ê³¤ì§€ì•” ë¦¬ì¡°íŠ¸ ìˆ˜ìš”ì˜ˆì¸¡ ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ!")
    print("ğŸ“Š ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")