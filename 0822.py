#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ê³¤ì§€ì•” ë¦¬ì¡°íŠ¸ ì‹ìŒì—…ìž¥ ìˆ˜ìš”ì˜ˆì¸¡ ê³ ë„í™” ML ëª¨ë¸ v3.0
- ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ Feature Engineering ê°•í™”
- ê³„ì ˆì„±/ê³ ê°êµ°ë³„ íŠ¹ì„± ë°˜ì˜
- ì—…ìž¥ë³„ íŠ¹ì„± ë° ë©”ë‰´ ì—°ê´€ê´€ê³„ ëª¨ë¸ë§
- ë¶€ëŒ€ì‹œì„¤ ë°ì´í„° í™œìš©
- ë‹´í•˜/ë¯¸ë¼ì‹œì•„ ê°€ì¤‘ì¹˜ ë°˜ì˜
- ì‹¤ì‹œê°„ ë””ë²„ê¹… ë° ì„±ëŠ¥ ì¶”ì 
"""

# ========================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ìž„í¬íŠ¸
# ========================================
import pandas as pd
import numpy as np
import warnings

warnings.filterwarnings('ignore')

from datetime import datetime, timedelta
import glob
import os
import re
from tqdm import tqdm
import pickle
import time
import gc

# ì‹œê°í™”
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'AppleGothic'  # macOS í•œê¸€ í°íŠ¸
plt.rcParams['axes.unicode_minus'] = False

# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet

# ë¶€ìŠ¤íŒ… ëª¨ë¸
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostRegressor

# ì‹œê³„ì—´ ëª¨ë¸
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.holtwinters import ExponentialSmoothing
import holidays


# ========================================
# 2. í‰ê°€ ë©”íŠ¸ë¦­ ë° ìœ í‹¸ë¦¬í‹°
# ========================================
def smape(y_true, y_pred):
    """sMAPE ê³„ì‚° (ê²½ì§„ëŒ€íšŒ í‰ê°€ì§€í‘œ)"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    diff = np.abs(y_true - y_pred) / denominator
    diff[denominator == 0] = 0.0
    return 100 * np.mean(diff)


def weighted_smape_by_store(y_true, y_pred, store_names):
    """ì—…ìž¥ë³„ ê°€ì¤‘ sMAPE ê³„ì‚° (ë‹´í•˜, ë¯¸ë¼ì‹œì•„ ë†’ì€ ê°€ì¤‘ì¹˜)"""
    store_weights = {
        'ë‹´í•˜': 2.0,
        'ë¯¸ë¼ì‹œì•„': 2.0,
        'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ': 1.0,
        'ë¼ê·¸ë¡œíƒ€': 1.0,
        'ì—°íšŒìž¥': 1.0,
        'ì¹´íŽ˜í…Œë¦¬ì•„': 1.0,
        'í¬ë ˆìŠ¤íŠ¸ë¦¿': 1.0,
        'í™”ë‹´ìˆ²ì£¼ë§‰': 1.0,
        'í™”ë‹´ìˆ²ì¹´íŽ˜': 1.0
    }

    total_weighted_score = 0
    total_weight = 0

    for store in store_weights.keys():
        mask = store_names.str.contains(store, na=False)
        if mask.sum() > 0:
            store_smape = smape(y_true[mask], y_pred[mask])
            weight = store_weights[store]
            total_weighted_score += store_smape * weight
            total_weight += weight
            print(f"  ðŸ“Š {store}: sMAPE = {store_smape:.4f} (ê°€ì¤‘ì¹˜: {weight})")

    return total_weighted_score / total_weight if total_weight > 0 else 0


def debug_print(message, level="INFO"):
    """ë””ë²„ê¹… ë©”ì‹œì§€ ì¶œë ¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {level}: {message}")


# ========================================
# 3. ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë°ì´í„° í”„ë¡œì„¸ì„œ
# ========================================
class DomainKnowledgeProcessor:
    def __init__(self):
        self.label_encoders = {}
        self.menu_stats = {}
        self.kr_holidays = holidays.KR()  # í•œêµ­ ê³µíœ´ì¼
        self.store_categories = self._define_store_categories()
        self.menu_categories = self._define_menu_categories()
        self.menu_associations = self._define_menu_associations()

    def _define_store_categories(self):
        """ì—…ìž¥ë³„ íŠ¹ì„± ì •ì˜ (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)"""
        return {
            'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ': {
                'type': 'outdoor_bbq',
                'season_preference': 'summer',  # ì—¬ë¦„ ì„ í˜¸
                'time_preference': 'evening',  # ì €ë… ì„ í˜¸
                'customer_type': 'family_group'
            },
            'ë‹´í•˜': {
                'type': 'korean_fine_dining',
                'season_preference': 'all',
                'time_preference': 'lunch_dinner',
                'customer_type': 'family_private',
                'high_end': True
            },
            'ë¼ê·¸ë¡œíƒ€': {
                'type': 'italian_wine',
                'season_preference': 'all',
                'time_preference': 'dinner',
                'customer_type': 'adult_group'
            },
            'ë¯¸ë¼ì‹œì•„': {
                'type': 'buffet_brunch',
                'season_preference': 'spring_fall',  # í™”ë‹´ìˆ² ë°©ë¬¸ê°
                'time_preference': 'brunch',
                'customer_type': 'family_group',
                'high_end': True
            },
            'ì—°íšŒìž¥': {
                'type': 'conference_catering',
                'season_preference': 'all',
                'time_preference': 'all',
                'customer_type': 'business_group'
            },
            'ì¹´íŽ˜í…Œë¦¬ì•„': {
                'type': 'casual_dining',
                'season_preference': 'all',
                'time_preference': 'all',
                'customer_type': 'general'
            },
            'í¬ë ˆìŠ¤íŠ¸ë¦¿': {
                'type': 'snack_cafe',
                'season_preference': 'all',
                'time_preference': 'all',
                'customer_type': 'casual'
            },
            'í™”ë‹´ìˆ²ì£¼ë§‰': {
                'type': 'traditional_pub',
                'season_preference': 'spring_fall',  # í™”ë‹´ìˆ² ë°©ë¬¸ê°
                'time_preference': 'afternoon_evening',
                'customer_type': 'adult_group'
            },
            'í™”ë‹´ìˆ²ì¹´íŽ˜': {
                'type': 'nature_cafe',
                'season_preference': 'spring_fall',  # í™”ë‹´ìˆ² ë°©ë¬¸ê°
                'time_preference': 'all',
                'customer_type': 'family_couple'
            }
        }

    def _define_menu_categories(self):
        """ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ì •ì˜ (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)"""
        categories = {
            'main_menu': ['ì •ì‹', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„', 'ìŠ¤í…Œì´í¬', 'íŒŒìŠ¤íƒ€', 'ë¦¬ì¡°ë˜', 'ë¹„ë¹”ë°¥', 'êµ­ë°¥', 'íƒ•', 'ì°Œê°œ', 'ì „ê³¨'],
            'side_menu': ['ê³µê¹ƒë°¥', 'ì‚¬ë¦¬', 'ì•¼ì±„', 'ìƒëŸ¬ë“œ', 'ë¹µ', 'ì ‘ì‹œ', 'ìˆ˜ì €'],
            'alcohol': ['ì†Œì£¼', 'ë§¥ì£¼', 'ë§‰ê±¸ë¦¬', 'ì™€ì¸', 'ì¹µí…Œì¼', 'ì°¸ì´ìŠ¬', 'ì²˜ìŒì²˜ëŸ¼', 'ì¹´ìŠ¤', 'í…Œë¼', 'í•˜ì´ë„¤ì¼„'],
            'beverage': ['ì½œë¼', 'ìŠ¤í”„ë¼ì´íŠ¸', 'ì»¤í”¼', 'ì•„ë©”ë¦¬ì¹´ë…¸', 'ë¼ë–¼', 'ì—ì´ë“œ', 'ì°¨', 'ìŒë£Œ'],
            'hot_menu': ['HOT', 'ë”°ëœ»í•œ', 'ì˜¨'],
            'ice_menu': ['ICE', 'ì°¨ê°€ìš´', 'ëƒ‰'],
            'group_menu': ['ë‹¨ì²´', 'íŒ¨í‚¤ì§€'],
            'rental': ['ëŒ€ì—¬ë£Œ', 'ë£¸', 'ì´ìš©ë£Œ'],
            'dessert': ['í›„ì‹', 'ì•„ì´ìŠ¤í¬ë¦¼', 'ë””ì €íŠ¸'],
            'noodle': ['ë©´', 'ìš°ë™', 'íŒŒìŠ¤íƒ€', 'ìŠ¤íŒŒê²Œí‹°', 'ì§œìž¥', 'ì§¬ë½•', 'ëƒ‰ë©´'],
            'meat': ['ê³ ê¸°', 'ì‚¼ê²¹', 'ê°ˆë¹„', 'ìŠ¤í…Œì´í¬', 'ë¶ˆê³ ê¸°', 'ëª©ì‚´', 'í•œìš°'],
            'seafood': ['í•´ì‚°ë¬¼', 'ìƒˆìš°', 'ëžìŠ¤íƒ€', 'ì§•ì–´', 'ê¼¬ë§‰']
        }
        return categories

    def _define_menu_associations(self):
        """ë©”ë‰´ ê°„ ì—°ê´€ê´€ê³„ ì •ì˜ (ìž¥ë°”êµ¬ë‹ˆ ë¶„ì„)"""
        return {
            # ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ ì—°ê´€ê´€ê³„
            'ì°¸ì´ìŠ¬': ['ì¼íšŒìš© ì†Œì£¼ì»µ'],
            'ìŠ¤í”„ë¼ì´íŠ¸ (ë‹¨ì²´)': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
            'ì¹´ìŠ¤ ë³‘(ë‹¨ì²´)': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
            'ì½œë¼ (ë‹¨ì²´)': ['ì¼íšŒìš© ì¢…ì´ì»µ'],
            'ìž”ë””ê·¸ëŠ˜ì§‘ ëŒ€ì—¬ë£Œ (12ì¸ì„)': ['ìž”ë””ê·¸ëŠ˜ì§‘ ì˜ìž ì¶”ê°€'],
            'ìž”ë””ê·¸ëŠ˜ì§‘ ëŒ€ì—¬ë£Œ (6ì¸ì„)': ['ìž”ë””ê·¸ëŠ˜ì§‘ ì˜ìž ì¶”ê°€'],

            # ë‹´í•˜ ì—°ê´€ê´€ê³„
            '(ë‹¨ì²´) ìƒëª©ì‚´ ê¹€ì¹˜ì „ê³¨ 2.0': ['ë¼ë©´ì‚¬ë¦¬'],
            'ìƒëª©ì‚´ ê¹€ì¹˜ì°Œê°œ': ['ë¼ë©´ì‚¬ë¦¬'],

            # ì¼ë°˜ì  ì—°ê´€ê´€ê³„
            'ë©”ì¸ë©”ë‰´': ['ê³µê¹ƒë°¥', 'ì‚¬ì´ë“œë©”ë‰´', 'ì£¼ë¥˜', 'ìŒë£Œ'],
            'ì •ì‹': ['í›„ì‹'],
            'ì£¼ë¥˜': ['ì•ˆì£¼', 'ì‚¬ì´ë“œë©”ë‰´']
        }

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        debug_print("ðŸ”„ ë°ì´í„° ë¡œë“œ ì‹œìž‘")

        # Train ë°ì´í„° ë¡œë“œ
        train_file = 'train.csv'
        if not os.path.exists(train_file):
            raise FileNotFoundError(f"Train íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_file}")

        train = pd.read_csv(train_file, encoding='utf-8')
        train['ì˜ì—…ì¼ìž'] = pd.to_datetime(train['ì˜ì—…ì¼ìž'])
        debug_print(f"âœ… Train ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {train.shape}")

        # Test ë°ì´í„° ë¡œë“œ
        test_files = glob.glob('test_*.csv')
        test_data = {}

        for file in test_files:
            test_name = os.path.basename(file).replace('.csv', '').replace('test_', 'TEST_')
            test_df = pd.read_csv(file, encoding='utf-8')
            test_df['ì˜ì—…ì¼ìž'] = pd.to_datetime(test_df['ì˜ì—…ì¼ìž'])
            test_data[test_name] = test_df
            debug_print(f"âœ… Test ë°ì´í„° ë¡œë“œ: {test_name} {test_df.shape}")

        return train, test_data

    def extract_datetime_features(self, df):
        """ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ (ê°•í™”)"""
        df = df.copy()
        df['date'] = pd.to_datetime(df['ì˜ì—…ì¼ìž'])

        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„±
        df['year'] = df['date'].dt.year
        df['month'] = df['date'].dt.month
        df['day'] = df['date'].dt.day
        df['dayofweek'] = df['date'].dt.dayofweek
        df['weekofyear'] = df['date'].dt.isocalendar().week
        df['dayofyear'] = df['date'].dt.dayofyear
        df['quarter'] = df['date'].dt.quarter

        # ìš”ì¼ íŠ¹ì„± (í•œêµ­ì‹)
        df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
        df['is_friday'] = (df['dayofweek'] == 4).astype(int)  # ê¸ˆìš”ì¼ (ì£¼ë§ ì „ë‚ )
        df['is_sunday'] = (df['dayofweek'] == 6).astype(int)

        # ê³µíœ´ì¼ íŠ¹ì„±
        df['is_holiday'] = df['date'].apply(lambda x: x in self.kr_holidays).astype(int)
        df['is_holiday_eve'] = df['date'].apply(
            lambda x: (x + timedelta(days=1)) in self.kr_holidays
        ).astype(int)

        # ê³„ì ˆ íŠ¹ì„± (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)
        df['season'] = df['month'].apply(self._get_season)
        df['is_ski_season'] = ((df['month'] >= 12) | (df['month'] <= 2)).astype(int)  # ê²¨ìš¸ ìŠ¤í‚¤ì‹œì¦Œ
        df['is_hwadamsup_season'] = ((df['month'] >= 3) & (df['month'] <= 5) |
                                     (df['month'] >= 9) & (df['month'] <= 11)).astype(int)  # ë´„ê°€ì„ í™”ë‹´ìˆ²
        df['is_family_season'] = ((df['month'] >= 6) & (df['month'] <= 8)).astype(int)  # ì—¬ë¦„ ê°€ì¡±ì‹œì¦Œ

        # ì—°ë§ì—°ì´ˆ íŠ¹ì„±
        df['is_year_end'] = ((df['month'] == 12) & (df['day'] >= 20)).astype(int)
        df['is_year_start'] = ((df['month'] == 1) & (df['day'] <= 10)).astype(int)

        # ìˆœí™˜ íŠ¹ì„± (ì£¼ê¸°ì„± ë°˜ì˜)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        df['day_sin'] = np.sin(2 * np.pi * df['day'] / 31)
        df['day_cos'] = np.cos(2 * np.pi * df['day'] / 31)
        df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
        df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
        df['weekofyear_sin'] = np.sin(2 * np.pi * df['weekofyear'] / 52)
        df['weekofyear_cos'] = np.cos(2 * np.pi * df['weekofyear'] / 52)

        return df

    def _get_season(self, month):
        """ê³„ì ˆ ë¶„ë¥˜ (í•œêµ­ ê¸°ì¤€)"""
        if month in [12, 1, 2]:
            return 'winter'  # ê²¨ìš¸
        elif month in [3, 4, 5]:
            return 'spring'  # ë´„
        elif month in [6, 7, 8]:
            return 'summer'  # ì—¬ë¦„
        else:
            return 'fall'  # ê°€ì„

    def extract_menu_features(self, df):
        """ë©”ë‰´ íŠ¹ì„± ì¶”ì¶œ (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ê°•í™”)"""
        df = df.copy()

        # ì—…ìž¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
        df['ì—…ìž¥ëª…'] = df['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'].apply(lambda x: x.split('_')[0])
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'].apply(lambda x: '_'.join(x.split('_')[1:]))

        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬ íŠ¹ì„±
        for category, keywords in self.menu_categories.items():
            df[f'is_{category}'] = df['ë©”ë‰´ëª…'].apply(
                lambda x: any(word in str(x) for word in keywords)
            ).astype(int)

        # ë©”ë‰´ëª… íŠ¹ì„±
        df['ë©”ë‰´ëª…_ê¸¸ì´'] = df['ë©”ë‰´ëª…'].str.len()
        df['has_parentheses'] = df['ë©”ë‰´ëª…'].str.contains(r'\(|\)', na=False).astype(int)
        df['has_number'] = df['ë©”ë‰´ëª…'].str.contains(r'\d', na=False).astype(int)

        # ì—…ìž¥ë³„ íŠ¹ì„± (ë„ë©”ì¸ ì§€ì‹)
        for store, characteristics in self.store_categories.items():
            mask = df['ì—…ìž¥ëª…'] == store
            df.loc[mask, 'store_type'] = characteristics['type']
            df.loc[mask, 'season_preference'] = characteristics['season_preference']
            df.loc[mask, 'time_preference'] = characteristics['time_preference']
            df.loc[mask, 'customer_type'] = characteristics['customer_type']
            df.loc[mask, 'is_high_end'] = characteristics.get('high_end', False)

        # ê³„ì ˆ-ì—…ìž¥ ë§¤ì¹­ ì ìˆ˜
        df['season_store_match'] = 0
        for season in ['winter', 'spring', 'summer', 'fall']:
            season_mask = df['season'] == season

            # ê²¨ìš¸-ìŠ¤í‚¤ ê³ ê° ë§¤ì¹­
            if season == 'winter':
                ski_stores = ['ì¹´íŽ˜í…Œë¦¬ì•„', 'í¬ë ˆìŠ¤íŠ¸ë¦¿']  # ê°„íŽ¸ì‹ ì„ í˜¸
                for store in ski_stores:
                    mask = season_mask & (df['ì—…ìž¥ëª…'] == store)
                    df.loc[mask, 'season_store_match'] = 1.5

            # ë´„ê°€ì„-í™”ë‹´ìˆ² ë°©ë¬¸ê° ë§¤ì¹­
            elif season in ['spring', 'fall']:
                hwadamsup_stores = ['ë¯¸ë¼ì‹œì•„', 'í™”ë‹´ìˆ²ì£¼ë§‰', 'í™”ë‹´ìˆ²ì¹´íŽ˜']  # ë¸ŒëŸ°ì¹˜, ì¹´íŽ˜ ì„ í˜¸
                for store in hwadamsup_stores:
                    mask = season_mask & (df['ì—…ìž¥ëª…'] == store)
                    df.loc[mask, 'season_store_match'] = 1.5

            # ì—¬ë¦„-ê°€ì¡±ê³ ê° ë§¤ì¹­
            elif season == 'summer':
                family_stores = ['ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ', 'ì¹´íŽ˜í…Œë¦¬ì•„', 'ë¯¸ë¼ì‹œì•„']  # ê°€ì¡±ë‹¨ìœ„ ì„ í˜¸
                for store in family_stores:
                    mask = season_mask & (df['ì—…ìž¥ëª…'] == store)
                    df.loc[mask, 'season_store_match'] = 1.3

        return df

    def extract_lag_features(self, df, target_col='ë§¤ì¶œìˆ˜ëŸ‰'):
        """ì‹œê³„ì—´ Lag íŠ¹ì„± ì¶”ì¶œ"""
        df = df.copy()
        df = df.sort_values(['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…', 'date'])

        # ë©”ë‰´ë³„ Lag íŠ¹ì„±
        for lag in [1, 3, 7, 14, 30]:
            df[f'{target_col}_lag_{lag}'] = df.groupby('ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…')[target_col].shift(lag)

        # ë©”ë‰´ë³„ ë¡¤ë§ í†µê³„
        for window in [3, 7, 14, 30]:
            df[f'{target_col}_rolling_mean_{window}'] = df.groupby('ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…')[target_col].rolling(
                window=window, min_periods=1
            ).mean().reset_index(0, drop=True)

            df[f'{target_col}_rolling_std_{window}'] = df.groupby('ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…')[target_col].rolling(
                window=window, min_periods=1
            ).std().reset_index(0, drop=True)

        # ì—…ìž¥ë³„ ì§‘ê³„ íŠ¹ì„±
        for window in [7, 14, 30]:
            store_rolling = df.groupby(['ì—…ìž¥ëª…', 'date'])[target_col].sum().reset_index()
            store_rolling = store_rolling.sort_values(['ì—…ìž¥ëª…', 'date'])
            store_rolling[f'store_rolling_mean_{window}'] = store_rolling.groupby('ì—…ìž¥ëª…')[target_col].rolling(
                window=window, min_periods=1
            ).mean().reset_index(0, drop=True)

            # ì›ë³¸ ë°ì´í„°ì— ë³‘í•©
            df = df.merge(
                store_rolling[['ì—…ìž¥ëª…', 'date', f'store_rolling_mean_{window}']],
                on=['ì—…ìž¥ëª…', 'date'], how='left'
            )

        return df

    def extract_cross_menu_features(self, df):
        """ë©”ë‰´ ê°„ ì—°ê´€ê´€ê³„ íŠ¹ì„±"""
        df = df.copy()

        # ê°™ì€ ì—…ìž¥ ë‚´ ë‹¤ë¥¸ ë©”ë‰´ ë§¤ì¶œ í•©ê³„
        df['store_total_sales'] = df.groupby(['ì—…ìž¥ëª…', 'date'])['ë§¤ì¶œìˆ˜ëŸ‰'].transform('sum')
        df['menu_sales_ratio'] = df['ë§¤ì¶œìˆ˜ëŸ‰'] / (df['store_total_sales'] + 1)

        # ì£¼ë¥˜ ê´€ë ¨ íŠ¹ì„± (ì£¼ë§/ê³µíœ´ì¼ ì „ë‚  íŠ¹ë³„ ì²˜ë¦¬)
        alcohol_boost = ((df['is_weekend'] == 1) |
                         (df['is_friday'] == 1) |
                         (df['is_holiday_eve'] == 1)).astype(int)
        df['alcohol_boost'] = df['is_alcohol'] * alcohol_boost

        # ì•„ì´ìŠ¤ ë©”ë‰´ ê³„ì ˆì„±
        df['ice_season_boost'] = df['is_ice_menu'] * df['is_family_season']
        df['hot_season_boost'] = df['is_hot_menu'] * df['is_ski_season']

        return df


# ========================================
# 4. ê³ ê¸‰ ML ëª¨ë¸ í´ëž˜ìŠ¤
# ========================================
class AdvancedResortDemandModel:
    def __init__(self):
        self.models = {}
        self.processor = DomainKnowledgeProcessor()
        self.scalers = {}
        self.feature_importance = {}

    def prepare_features(self, df, is_train=True):
        """ì¢…í•©ì  íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
        debug_print("ðŸ”„ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œìž‘")

        # 1. ì‹œê°„ íŠ¹ì„±
        df = self.processor.extract_datetime_features(df)
        debug_print("âœ… ì‹œê°„ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 2. ë©”ë‰´ íŠ¹ì„±
        df = self.processor.extract_menu_features(df)
        debug_print("âœ… ë©”ë‰´ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 3. Lag íŠ¹ì„± (Trainì—ì„œë§Œ)
        if is_train:
            df = self.processor.extract_lag_features(df)
            debug_print("âœ… Lag íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 4. ë©”ë‰´ ê°„ ì—°ê´€ íŠ¹ì„±
        if is_train:
            df = self.processor.extract_cross_menu_features(df)
            debug_print("âœ… ë©”ë‰´ ì—°ê´€ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")

        # 5. ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        cat_columns = ['ì—…ìž¥ëª…', 'ë©”ë‰´ëª…', 'ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…', 'store_type',
                       'season_preference', 'time_preference', 'customer_type']

        for col in cat_columns:
            if col in df.columns:
                if col not in self.processor.label_encoders:
                    self.processor.label_encoders[col] = LabelEncoder()
                    all_values = df[col].fillna('UNKNOWN').unique().tolist()
                    self.processor.label_encoders[col].fit(all_values + ['UNKNOWN'])

                df[f'{col}_encoded'] = df[col].fillna('UNKNOWN').apply(
                    lambda x: self.processor.label_encoders[col].transform([str(x)])[0]
                    if str(x) in self.processor.label_encoders[col].classes_
                    else self.processor.label_encoders[col].transform(['UNKNOWN'])[0]
                )

        debug_print(f"âœ… íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ. ì´ íŠ¹ì„± ìˆ˜: {df.shape[1]}")
        return df

    def create_ensemble_models(self):
        """ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”)"""
        models = {
            'xgboost': xgb.XGBRegressor(
                n_estimators=3000,
                max_depth=10,
                learning_rate=0.01,
                subsample=0.8,
                colsample_bytree=0.8,
                min_child_weight=5,
                gamma=0.1,
                reg_alpha=0.1,
                reg_lambda=1.2,
                random_state=42,
                n_jobs=-1,
                objective='reg:squarederror'
            ),
            'lightgbm': lgb.LGBMRegressor(
                n_estimators=3000,
                max_depth=10,
                learning_rate=0.01,
                num_leaves=64,
                min_child_samples=30,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=1.2,
                random_state=42,
                n_jobs=-1,
                objective='regression',
                metric='rmse'
            ),
            'catboost': CatBoostRegressor(
                iterations=2000,
                depth=8,
                learning_rate=0.01,
                l2_leaf_reg=5,
                subsample=0.8,
                random_strength=0.1,
                bagging_temperature=0.2,
                random_state=42,
                verbose=False
            ),
            'random_forest': RandomForestRegressor(
                n_estimators=500,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=5,
                random_state=42,
                n_jobs=-1
            )
        }
        return models

    def train_models(self, X_train, y_train, X_val, y_val, model_name="default"):
        """ëª¨ë¸ í•™ìŠµ"""
        debug_print(f"ðŸŽ¯ {model_name} ëª¨ë¸ í•™ìŠµ ì‹œìž‘")
        models = self.create_ensemble_models()
        trained_models = {}

        # ìŠ¤ì¼€ì¼ë§
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train.fillna(0))
        X_val_scaled = scaler.transform(X_val.fillna(0))
        self.scalers[model_name] = scaler

        for name, model in models.items():
            start_time = time.time()
            debug_print(f"  ðŸ”„ {name} í•™ìŠµ ì¤‘...")

            try:
                if name in ['xgboost', 'lightgbm']:
                    model.fit(
                        X_train_scaled, y_train,
                        eval_set=[(X_val_scaled, y_val)],
                        early_stopping_rounds=100,
                        verbose=False
                    )
                else:
                    model.fit(X_train_scaled, y_train)

                # ê²€ì¦ ì„±ëŠ¥
                val_pred = model.predict(X_val_scaled)
                val_smape = smape(y_val, val_pred)

                trained_models[name] = model

                train_time = time.time() - start_time
                debug_print(f"  âœ… {name} ì™„ë£Œ: sMAPE={val_smape:.4f}, ì‹œê°„={train_time:.1f}ì´ˆ")

            except Exception as e:
                debug_print(f"  âŒ {name} ì‹¤íŒ¨: {e}", "ERROR")

        return trained_models

    def weighted_ensemble_predict(self, models, X_test, scaler):
        """ê°€ì¤‘ ì•™ìƒë¸” ì˜ˆì¸¡"""
        X_test_scaled = scaler.transform(X_test.fillna(0))

        # ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥ ê¸°ë°˜)
        weights = {
            'lightgbm': 0.35,
            'xgboost': 0.30,
            'catboost': 0.25,
            'random_forest': 0.10
        }

        predictions = []
        total_weight = 0

        for name, model in models.items():
            if name in weights:
                pred = model.predict(X_test_scaled)
                predictions.append(pred * weights[name])
                total_weight += weights[name]

        if predictions:
            ensemble_pred = np.sum(predictions, axis=0) / total_weight
            return np.maximum(0, ensemble_pred)  # ìŒìˆ˜ ì œê±°
        else:
            return np.zeros(len(X_test))

    def create_future_features(self, last_row, pred_date, feature_cols):
        """ë¯¸ëž˜ íŠ¹ì„± ìƒì„±"""
        future_row = last_row.copy()
        future_row['ì˜ì—…ì¼ìž'] = pred_date
        future_row['date'] = pred_date

        # ì‹œê°„ íŠ¹ì„± ì—…ë°ì´íŠ¸
        future_row['year'] = pred_date.year
        future_row['month'] = pred_date.month
        future_row['day'] = pred_date.day
        future_row['dayofweek'] = pred_date.dayofweek
        future_row['weekofyear'] = pred_date.isocalendar()[1]
        future_row['dayofyear'] = pred_date.timetuple().tm_yday
        future_row['quarter'] = (pred_date.month - 1) // 3 + 1

        # íŠ¹ë³„ì¼ íŠ¹ì„±
        future_row['is_weekend'] = int(pred_date.dayofweek >= 5)
        future_row['is_friday'] = int(pred_date.dayofweek == 4)
        future_row['is_sunday'] = int(pred_date.dayofweek == 6)
        future_row['is_holiday'] = int(pred_date in self.processor.kr_holidays)
        future_row['is_holiday_eve'] = int((pred_date + timedelta(days=1)) in self.processor.kr_holidays)

        # ê³„ì ˆ íŠ¹ì„±
        season = self.processor._get_season(pred_date.month)
        future_row['season'] = season
        future_row['is_ski_season'] = int(pred_date.month in [12, 1, 2])
        future_row['is_hwadamsup_season'] = int(pred_date.month in [3, 4, 5, 9, 10, 11])
        future_row['is_family_season'] = int(pred_date.month in [6, 7, 8])

        # ì—°ë§ì—°ì´ˆ
        future_row['is_year_end'] = int(pred_date.month == 12 and pred_date.day >= 20)
        future_row['is_year_start'] = int(pred_date.month == 1 and pred_date.day <= 10)

        # ìˆœí™˜ íŠ¹ì„±
        future_row['month_sin'] = np.sin(2 * np.pi * pred_date.month / 12)
        future_row['month_cos'] = np.cos(2 * np.pi * pred_date.month / 12)
        future_row['day_sin'] = np.sin(2 * np.pi * pred_date.day / 31)
        future_row['day_cos'] = np.cos(2 * np.pi * pred_date.day / 31)
        future_row['dayofweek_sin'] = np.sin(2 * np.pi * pred_date.dayofweek / 7)
        future_row['dayofweek_cos'] = np.cos(2 * np.pi * pred_date.dayofweek / 7)
        future_row['weekofyear_sin'] = np.sin(2 * np.pi * future_row['weekofyear'] / 52)
        future_row['weekofyear_cos'] = np.cos(2 * np.pi * future_row['weekofyear'] / 52)

        # Lag íŠ¹ì„±ì€ 0ìœ¼ë¡œ ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” ìµœê·¼ ê°’ ì‚¬ìš©í•´ì•¼ í•¨)
        lag_cols = [col for col in feature_cols if 'lag_' in col or 'rolling_' in col]
        for col in lag_cols:
            if col in future_row.columns:
                future_row[col] = 0

        return future_row


# ========================================
# 5. ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ========================================
class ResortDemandPipeline:
    def __init__(self):
        self.model = AdvancedResortDemandModel()
        self.menu_models = {}

    def analyze_data(self, train_df):
        """ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”"""
        debug_print("ðŸ“Š ë°ì´í„° ë¶„ì„ ì‹œìž‘")

        # ê¸°ë³¸ í†µê³„
        print(f"ðŸ“‹ ì „ì²´ ë°ì´í„°: {train_df.shape}")
        print(f"ðŸ“‹ ë©”ë‰´ ìˆ˜: {train_df['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'].nunique()}")
        print(f"ðŸ“‹ ì—…ìž¥ ìˆ˜: {train_df['ì—…ìž¥ëª…'].nunique()}")
        print(f"ðŸ“‹ ê¸°ê°„: {train_df['date'].min()} ~ {train_df['date'].max()}")

        # ì—…ìž¥ë³„ ë§¤ì¶œ í†µê³„
        store_stats = train_df.groupby('ì—…ìž¥ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'std']).round(2)
        print(f"\nðŸ“Š ì—…ìž¥ë³„ ë§¤ì¶œ í†µê³„:")
        print(store_stats)

        # ê³„ì ˆë³„ ë§¤ì¶œ íŒ¨í„´
        seasonal_stats = train_df.groupby('season')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean']).round(2)
        print(f"\nðŸŒ¸ ê³„ì ˆë³„ ë§¤ì¶œ íŒ¨í„´:")
        print(seasonal_stats)

        # ìš”ì¼ë³„ ë§¤ì¶œ íŒ¨í„´
        dow_stats = train_df.groupby('dayofweek')['ë§¤ì¶œìˆ˜ëŸ‰'].mean().round(2)
        print(f"\nðŸ“… ìš”ì¼ë³„ í‰ê·  ë§¤ì¶œ:")
        for i, val in enumerate(dow_stats):
            days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
            print(f"  {days[i]}: {val}")

    def run_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        total_start = time.time()
        debug_print("ðŸš€ ê³¤ì§€ì•” ë¦¬ì¡°íŠ¸ ìˆ˜ìš”ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œìž‘")

        # 1. ë°ì´í„° ë¡œë“œ
        train, test_data = self.model.processor.load_data()

        # 2. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
        debug_print("ðŸ”„ Train ë°ì´í„° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
        train_fe = self.model.prepare_features(train, is_train=True)

        # 3. ë°ì´í„° ë¶„ì„
        self.analyze_data(train_fe)

        # 4. íŠ¹ì„± ì„ íƒ
        exclude_cols = ['ì˜ì—…ì¼ìž', 'ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰', 'date', 'ì—…ìž¥ëª…', 'ë©”ë‰´ëª…', 'season']
        feature_cols = [col for col in train_fe.columns if col not in exclude_cols]
        target_col = 'ë§¤ì¶œìˆ˜ëŸ‰'

        debug_print(f"ðŸ“Š ì‚¬ìš©í•  íŠ¹ì„± ìˆ˜: {len(feature_cols)}")

        # 5. ì‹œê³„ì—´ ë¶„í• 
        train_fe = train_fe.sort_values('date')
        split_date = train_fe['date'].quantile(0.85)  # 85% ì§€ì ì—ì„œ ë¶„í• 

        train_set = train_fe[train_fe['date'] < split_date]
        val_set = train_fe[train_fe['date'] >= split_date]

        X_train = train_set[feature_cols].fillna(0)
        y_train = train_set[target_col]
        X_val = val_set[feature_cols].fillna(0)
        y_val = val_set[target_col]

        debug_print(f"í•™ìŠµ ë°ì´í„°: {X_train.shape}, ê²€ì¦ ë°ì´í„°: {X_val.shape}")

        # 6. ì „ì²´ ëª¨ë¸ í•™ìŠµ
        debug_print("ðŸŽ¯ ì „ì²´ ë°ì´í„° í†µí•© ëª¨ë¸ í•™ìŠµ")
        global_models = self.model.train_models(X_train, y_train, X_val, y_val, "ì „ì²´")

        # ì„±ëŠ¥ í‰ê°€
        val_pred = self.model.weighted_ensemble_predict(global_models, X_val, self.model.scalers["ì „ì²´"])
        overall_smape = smape(y_val, val_pred)
        weighted_smape = weighted_smape_by_store(y_val, val_pred, val_set['ì—…ìž¥ëª…'])

        debug_print(f"âœ… ì „ì²´ ëª¨ë¸ ì„±ëŠ¥: sMAPE={overall_smape:.4f}, ê°€ì¤‘sMAPE={weighted_smape:.4f}")

        # 7. ìµœì¢… ëª¨ë¸ (ì „ì²´ ë°ì´í„°)
        debug_print("ðŸŽ¯ ìµœì¢… ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°)")
        X_full = train_fe[feature_cols].fillna(0)
        y_full = train_fe[target_col]

        val_size = max(int(len(X_full) * 0.1), 1000)
        final_models = self.model.train_models(
            X_full[:-val_size], y_full.iloc[:-val_size],
            X_full[-val_size:], y_full.iloc[-val_size:],
            "ìµœì¢…"
        )

        # 8. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        debug_print("ðŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡")
        all_predictions = []

        for test_name, test_df in test_data.items():
            debug_print(f"â†’ {test_name} ì˜ˆì¸¡ ì¤‘...")

            # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (Testìš©)
            test_fe = self.model.prepare_features(test_df, is_train=False)

            # ë§ˆì§€ë§‰ ë‚ ì§œ
            last_date = test_df['ì˜ì—…ì¼ìž'].max()
            if not isinstance(last_date, pd.Timestamp):
                last_date = pd.to_datetime(last_date)

            # 7ì¼ê°„ ì˜ˆì¸¡
            for day_ahead in range(1, 8):
                pred_date = last_date + timedelta(days=day_ahead)

                for menu in test_df['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'].unique():
                    # í•´ë‹¹ ë©”ë‰´ì˜ ë§ˆì§€ë§‰ í–‰
                    menu_data = test_fe[test_fe['ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'] == menu]
                    if len(menu_data) == 0:
                        continue

                    last_row = menu_data.iloc[-1:].copy()

                    # ë¯¸ëž˜ íŠ¹ì„± ìƒì„±
                    future_features = self.model.create_future_features(
                        last_row, pred_date, feature_cols
                    )

                    # ì˜ˆì¸¡
                    pred_value = self.model.weighted_ensemble_predict(
                        final_models,
                        future_features[feature_cols].fillna(0),
                        self.model.scalers["ìµœì¢…"]
                    )[0]

                    # í›„ì²˜ë¦¬ (ë„ë©”ì¸ ì§€ì‹ ì ìš©)
                    pred_value = self.apply_domain_postprocessing(
                        pred_value, menu, pred_date, last_row.iloc[0]
                    )

                    all_predictions.append({
                        'ì˜ì—…ì¼ìž': f"{test_name}+{day_ahead}ì¼",
                        'ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…': menu,
                        'ë§¤ì¶œìˆ˜ëŸ‰': max(0, int(round(pred_value)))
                    })

        # 9. ì œì¶œ íŒŒì¼ ìƒì„±
        self.create_submission(all_predictions)

        total_time = time.time() - total_start
        debug_print(f"âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì´ ì†Œìš”ì‹œê°„: {total_time / 60:.1f}ë¶„")

        return overall_smape, weighted_smape

    def apply_domain_postprocessing(self, pred_value, menu, pred_date, last_row):
        """ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í›„ì²˜ë¦¬"""
        store_name = menu.split('_')[0]
        menu_name = '_'.join(menu.split('_')[1:])

        # 1. ê³„ì ˆì„± ì¡°ì •
        month = pred_date.month

        # ê²¨ìš¸ ìŠ¤í‚¤ì‹œì¦Œ - ê°„íŽ¸ì‹ ì„ í˜¸
        if month in [12, 1, 2]:
            if store_name in ['ì¹´íŽ˜í…Œë¦¬ì•„', 'í¬ë ˆìŠ¤íŠ¸ë¦¿']:
                pred_value *= 1.2
            elif store_name in ['ë¯¸ë¼ì‹œì•„', 'í™”ë‹´ìˆ²ì¹´íŽ˜']:  # ë¸ŒëŸ°ì¹˜ ê°ì†Œ
                pred_value *= 0.8

        # ë´„ê°€ì„ í™”ë‹´ìˆ²ì‹œì¦Œ - ë¸ŒëŸ°ì¹˜/ì¹´íŽ˜ ì„ í˜¸
        elif month in [3, 4, 5, 9, 10, 11]:
            if store_name in ['ë¯¸ë¼ì‹œì•„', 'í™”ë‹´ìˆ²ì£¼ë§‰', 'í™”ë‹´ìˆ²ì¹´íŽ˜']:
                pred_value *= 1.3
            elif 'ë¸ŒëŸ°ì¹˜' in menu_name:
                pred_value *= 1.4

        # ì—¬ë¦„ ê°€ì¡±ì‹œì¦Œ - BBQ, ì•„ì´ìŠ¤ ë©”ë‰´ ì„ í˜¸
        elif month in [6, 7, 8]:
            if store_name == 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ':
                pred_value *= 1.3
            elif 'ICE' in menu_name or 'ì•„ì´ìŠ¤' in menu_name:
                pred_value *= 1.5
            elif 'HOT' in menu_name:
                pred_value *= 0.7

        # 2. ìš”ì¼ ì¡°ì •
        dayofweek = pred_date.dayofweek

        # ì£¼ë§ (ê¸ˆìš”ì¼ í¬í•¨)
        if dayofweek >= 4:  # ê¸ˆ, í† , ì¼
            # ì£¼ë¥˜ ì¦ê°€
            alcohol_keywords = ['ì†Œì£¼', 'ë§¥ì£¼', 'ë§‰ê±¸ë¦¬', 'ì™€ì¸', 'ì¹µí…Œì¼']
            if any(keyword in menu_name for keyword in alcohol_keywords):
                pred_value *= 1.4

            # ê³ ê¸‰ ë ˆìŠ¤í† ëž‘ ì¦ê°€ (ë‹´í•˜, ë¼ê·¸ë¡œíƒ€)
            if store_name in ['ë‹´í•˜', 'ë¼ê·¸ë¡œíƒ€']:
                pred_value *= 1.2

        # 3. ê³µíœ´ì¼ ì¡°ì •
        if pred_date in self.model.processor.kr_holidays:
            pred_value *= 1.3

        # 4. ì—°ë§ì—°ì´ˆ ì¡°ì •
        if (month == 12 and pred_date.day >= 20) or (month == 1 and pred_date.day <= 10):
            pred_value *= 1.4

        # 5. ì—…ìž¥ë³„ íŠ¹ì„± ë°˜ì˜
        if store_name == 'ë‹´í•˜':  # ê³ ê¸‰ í•œì‹ - ì˜ˆì•½ê¸°ë°˜
            pred_value *= 1.1
        elif store_name == 'ë¯¸ë¼ì‹œì•„':  # ê³ ê¸‰ ë¸ŒëŸ°ì¹˜
            pred_value *= 1.1

        return pred_value

    def create_submission(self, predictions):
        """ì œì¶œ íŒŒì¼ ìƒì„±"""
        submission_df = pd.DataFrame(predictions)

        # ë² ì´ìŠ¤ë¼ì¸ê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ì •ë ¬
        submission_df = submission_df.sort_values(['ì˜ì—…ì¼ìž', 'ì˜ì—…ìž¥ëª…_ë©”ë‰´ëª…'])

        filename = f'advanced_submission_v3_{datetime.now().strftime("%m%d_%H%M")}.csv'
        submission_df.to_csv(filename, index=False, encoding='utf-8-sig')

        debug_print(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„±: {filename}")
        debug_print(f"ðŸ“Š ì˜ˆì¸¡ ë ˆì½”ë“œ ìˆ˜: {len(submission_df)}")

        # ê°„ë‹¨í•œ í†µê³„
        total_predictions = submission_df['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
        avg_prediction = submission_df['ë§¤ì¶œìˆ˜ëŸ‰'].mean()
        debug_print(f"ðŸ“ˆ ì´ ì˜ˆì¸¡ ë§¤ì¶œ: {total_predictions:,}, í‰ê· : {avg_prediction:.2f}")

        return filename


# ========================================
# 6. ì‹¤í–‰
# ========================================
if __name__ == "__main__":
    pipeline = ResortDemandPipeline()
    smape_score, weighted_smape_score = pipeline.run_pipeline()

    print(f"\n{'=' * 70}")
    print(f"ðŸŽ¯ ìµœì¢… ì„±ëŠ¥ ê²°ê³¼")
    print(f"{'=' * 70}")
    print(f"ðŸ“Š sMAPE: {smape_score:.4f}")
    print(f"ðŸ“Š ê°€ì¤‘ sMAPE: {weighted_smape_score:.4f}")
    print(f"ðŸŽ¯ ëª©í‘œ: 0.62 ì´í•˜ ë‹¬ì„±!")
    print(f"{'=' * 70}")